{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Telco Customer Churn - Data Exploration\n",
    "\n",
    "This notebook explores the Telco Customer Churn dataset from Kaggle.\n",
    "\n",
    "**Dataset**: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "\n",
    "**Objective**: Understand the dataset structure, features, and target variable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Load Dataset\n",
    "\n",
    "**Note**: Download the dataset from Kaggle and place it in the `../data/` folder as `Telco-Customer-Churn.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Telco Customer Churn dataset\n",
    "try:\n",
    "    df = pd.read_csv('../data/Telco-Customer-Churn.csv')\n",
    "    print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\nexcept FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"Please download from: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\")\n",
    "    print(\"And save as: '../data/Telco-Customer-Churn.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column information\n",
    "print(\"üìù COLUMN INFORMATION\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\nüìà DATA TYPES\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\nDetailed data types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable (Churn)\n",
    "print(\"üéØ TARGET VARIABLE ANALYSIS\")\n",
    "\n",
    "if 'Churn' in df.columns:\n",
    "    print(\"\\nChurn distribution:\")\n",
    "    churn_counts = df['Churn'].value_counts()\n",
    "    churn_percentages = df['Churn'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    churn_summary = pd.DataFrame({\n",
    "        'Count': churn_counts,\n",
    "        'Percentage': churn_percentages\n",
    "    })\n",
    "    print(churn_summary)\n",
    "    \n",
    "    # Convert to binary\n",
    "    df['Churn_Binary'] = (df['Churn'] == 'Yes').astype(int)\n",
    "    \n",
    "    print(f\"\\nüìä Overall churn rate: {df['Churn_Binary'].mean():.1%}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Pie chart\n",
    "    churn_counts.plot(kind='pie', ax=axes[0], autopct='%1.1f%%', startangle=90)\n",
    "    axes[0].set_title('Churn Distribution')\n",
    "    axes[0].set_ylabel('')\n",
    "    \n",
    "    # Bar chart\n",
    "    churn_counts.plot(kind='bar', ax=axes[1], color=['skyblue', 'salmon'])\n",
    "    axes[1].set_title('Churn Count')\n",
    "    axes[1].set_xlabel('Churn')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"‚ùå 'Churn' column not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "print(\"‚ùì MISSING VALUES ANALYSIS\")\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_values,\n",
    "    'Missing_Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_df)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_df['Missing_Percentage'].plot(kind='bar')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.ylabel('Percentage Missing')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"‚úÖ No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical features\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target from categorical if present\n",
    "if 'Churn' in categorical_cols:\n",
    "    categorical_cols.remove('Churn')\n",
    "\n",
    "print(f\"üìä FEATURE TYPES\")\n",
    "print(f\"Numerical features ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features analysis\n",
    "if len(numerical_cols) > 0:\n",
    "    print(\"üìà NUMERICAL FEATURES STATISTICS\")\n",
    "    numerical_stats = df[numerical_cols].describe()\n",
    "    print(numerical_stats)\n",
    "    \n",
    "    # Plot distributions\n",
    "    if len(numerical_cols) > 0:\n",
    "        n_cols = min(3, len(numerical_cols))\n",
    "        n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "        axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "        \n",
    "        for i, col in enumerate(numerical_cols):\n",
    "            if i < len(axes):\n",
    "                df[col].hist(bins=30, ax=axes[i], alpha=0.7)\n",
    "                axes[i].set_title(f'Distribution of {col}')\n",
    "                axes[i].set_xlabel(col)\n",
    "                axes[i].set_ylabel('Frequency')\n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for i in range(len(numerical_cols), len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"üìù CATEGORICAL FEATURES ANALYSIS\")\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Unique values: {unique_count}\")\n",
    "        \n",
    "        if unique_count <= 10:  # Show value counts for columns with <= 10 unique values\n",
    "            value_counts = df[col].value_counts()\n",
    "            print(f\"  Value counts:\")\n",
    "            for value, count in value_counts.head().items():\n",
    "                print(f\"    {value}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  Top 5 values: {df[col].value_counts().head().index.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Churn Analysis by Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze churn by categorical features\n",
    "if 'Churn_Binary' in df.columns and len(categorical_cols) > 0:\n",
    "    print(\"üìä CHURN ANALYSIS BY CATEGORICAL FEATURES\")\n",
    "    \n",
    "    # Select top categorical features for visualization\n",
    "    top_categorical = categorical_cols[:6]  # Show first 6 categorical features\n",
    "    \n",
    "    n_cols = 3\n",
    "    n_rows = (len(top_categorical) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "    \n",
    "    for i, col in enumerate(top_categorical):\n",
    "        if i < len(axes):\n",
    "            # Calculate churn rate by category\n",
    "            churn_by_category = df.groupby(col)['Churn_Binary'].agg(['count', 'mean']).reset_index()\n",
    "            churn_by_category.columns = [col, 'Total_Customers', 'Churn_Rate']\n",
    "            \n",
    "            # Plot\n",
    "            churn_by_category.plot(x=col, y='Churn_Rate', kind='bar', ax=axes[i], \n",
    "                                 color='coral', alpha=0.7)\n",
    "            axes[i].set_title(f'Churn Rate by {col}')\n",
    "            axes[i].set_ylabel('Churn Rate')\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "            axes[i].legend().set_visible(False)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(top_categorical), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numerical features\n",
    "if len(numerical_cols) > 1:\n",
    "    print(\"üìà CORRELATION ANALYSIS\")\n",
    "    \n",
    "    # Add binary churn for correlation\n",
    "    correlation_cols = numerical_cols.copy()\n",
    "    if 'Churn_Binary' in df.columns:\n",
    "        correlation_cols.append('Churn_Binary')\n",
    "    \n",
    "    correlation_matrix = df[correlation_cols].corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show correlation with churn\n",
    "    if 'Churn_Binary' in df.columns:\n",
    "        print(\"\\nüéØ Correlation with Churn:\")\n",
    "        churn_correlation = correlation_matrix['Churn_Binary'].drop('Churn_Binary').sort_values(key=abs, ascending=False)\n",
    "        print(churn_correlation)\nelse:\n",
    "    print(\"üìà Not enough numerical features for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data with binary churn column\n",
    "if 'Churn_Binary' in df.columns:\n",
    "    df.to_csv('../data/telco_processed_basic.csv', index=False)\n",
    "    print(\"‚úÖ Processed data saved as '../data/telco_processed_basic.csv'\")\n",
    "\n",
    "print(\"\\nüìã SUMMARY:\")\n",
    "print(f\"‚úÖ Dataset successfully explored\")\n",
    "print(f\"‚úÖ {df.shape[0]:,} customers analyzed\")\n",
    "print(f\"‚úÖ {df.shape[1]} features identified\")\nif 'Churn_Binary' in df.columns:\n",
    "    print(f\"‚úÖ Churn rate: {df['Churn_Binary'].mean():.1%}\")\n",
    "print(f\"‚úÖ Ready for feature engineering and modeling\")\n",
    "\n",
    "print(\"\\nüöÄ Next steps:\")\n",
    "print(\"1. Run notebook: 02_feature_engineering.ipynb\")\n",
    "print(\"2. Run notebook: 03_exploratory_data_analysis.ipynb\")\n",
    "print(\"3. Run notebook: 04_machine_learning_models.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}