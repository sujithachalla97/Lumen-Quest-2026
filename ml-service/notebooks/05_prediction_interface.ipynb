{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ Telco Customer Churn - Production Prediction Interface\n",
    "\n",
    "This notebook creates a production-ready prediction interface for the churn prediction model.\n",
    "\n",
    "**Objectives**:\n",
    "- Load trained model and preprocessing components\n",
    "- Create prediction functions for single customers and batches\n",
    "- Provide business-friendly prediction results\n",
    "- Generate actionable recommendations\n",
    "- Create deployment-ready prediction system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ¯ Prediction Interface Libraries Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Load Trained Model and Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and related components\n",
    "print(\"ğŸ“¥ LOADING TRAINED MODEL AND COMPONENTS\")\n",
    "\n",
    "try:\n",
    "    # Load model metadata first\n",
    "    model_metadata = pd.read_csv('../models/model_metadata.csv').iloc[0]\n",
    "    print(f\"âœ… Model metadata loaded\")\n",
    "    print(f\"Model: {model_metadata['model_name']}\")\n",
    "    print(f\"ROC-AUC: {model_metadata['roc_auc_score']:.4f}\")\n",
    "    print(f\"Requires scaling: {model_metadata['requires_scaling']}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model_name = model_metadata['model_name'].lower().replace(' ', '_')\n",
    "    model = joblib.load(f'../models/best_churn_model_{model_name}.pkl')\n",
    "    print(f\"âœ… Model loaded: {type(model).__name__}\")\n",
    "    \n",
    "    # Load feature names\n",
    "    feature_names = joblib.load('../models/feature_names.pkl')\n",
    "    print(f\"âœ… Feature names loaded: {len(feature_names)} features\")\n",
    "    \n",
    "    # Load scaler if needed\n",
    "    scaler = None\n",
    "    if model_metadata['requires_scaling']:\n",
    "        scaler = joblib.load('../models/feature_scaler.pkl')\n",
    "        print(f\"âœ… Feature scaler loaded\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Model ready for predictions!\")\n",
    "    \nexcept FileNotFoundError as e:\n",
    "    print(f\"âŒ Model files not found: {e}\")\n",
    "    print(\"Please run notebook 04_machine_learning_models.ipynb first\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Create Prediction Interface Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive prediction interface class\n",
    "class TelcoChurnPredictor:\n",
    "    \"\"\"\n",
    "    Production-ready churn prediction interface for Telco customers.\n",
    "    \n",
    "    This class provides methods for:\n",
    "    - Single customer churn prediction\n",
    "    - Batch prediction for multiple customers\n",
    "    - Risk level classification\n",
    "    - Business recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, feature_names, scaler=None, model_metadata=None):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with trained model and components.\n",
    "        \n",
    "        Parameters:\n",
    "        - model: Trained machine learning model\n",
    "        - feature_names: List of feature names expected by the model\n",
    "        - scaler: Feature scaler (if model requires scaling)\n",
    "        - model_metadata: Dictionary with model performance metrics\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.scaler = scaler\n",
    "        self.model_metadata = model_metadata\n",
    "        \n",
    "        print(f\"ğŸ¤– TelcoChurnPredictor initialized\")\n",
    "        print(f\"   Model: {type(model).__name__}\")\n",
    "        print(f\"   Features: {len(feature_names)}\")\n",
    "        print(f\"   Scaling: {'Yes' if scaler is not None else 'No'}\")\n",
    "    \n",
    "    def predict_single_customer(self, customer_data):\n",
    "        \"\"\"\n",
    "        Predict churn probability for a single customer.\n",
    "        \n",
    "        Parameters:\n",
    "        - customer_data: Dictionary or pandas Series with customer features\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary with prediction results and recommendations\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert to DataFrame if needed\n",
    "            if isinstance(customer_data, dict):\n",
    "                df = pd.DataFrame([customer_data])\n",
    "            elif isinstance(customer_data, pd.Series):\n",
    "                df = pd.DataFrame([customer_data])\n",
    "            else:\n",
    "                df = customer_data\n",
    "            \n",
    "            # Ensure all required features are present\n",
    "            for feature in self.feature_names:\n",
    "                if feature not in df.columns:\n",
    "                    df[feature] = 0  # Default value for missing features\n",
    "            \n",
    "            # Select and order features\n",
    "            X = df[self.feature_names]\n",
    "            \n",
    "            # Apply scaling if needed\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X)\n",
    "                X_final = X_scaled\n",
    "            else:\n",
    "                X_final = X\n",
    "            \n",
    "            # Make prediction\n",
    "            churn_probability = self.model.predict_proba(X_final)[0, 1]\n",
    "            prediction = self.model.predict(X_final)[0]\n",
    "            \n",
    "            # Determine risk level\n",
    "            risk_level = self._get_risk_level(churn_probability)\n",
    "            \n",
    "            # Generate recommendations\n",
    "            recommendations = self._get_recommendations(churn_probability, customer_data)\n",
    "            \n",
    "            return {\n",
    "                'churn_probability': round(churn_probability, 4),\n",
    "                'prediction': 'Will Churn' if prediction == 1 else 'Will Stay',\n",
    "                'risk_level': risk_level,\n",
    "                'confidence': self._get_confidence_level(churn_probability),\n",
    "                'recommendations': recommendations,\n",
    "                'key_factors': self._get_key_factors(X.iloc[0])\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': f\"Prediction failed: {str(e)}\"}\n",
    "    \n",
    "    def predict_batch(self, customers_data):\n",
    "        \"\"\"\n",
    "        Predict churn for multiple customers.\n",
    "        \n",
    "        Parameters:\n",
    "        - customers_data: DataFrame with customer features\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with original data plus prediction results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = customers_data.copy()\n",
    "            \n",
    "            # Ensure all required features are present\n",
    "            for feature in self.feature_names:\n",
    "                if feature not in df.columns:\n",
    "                    df[feature] = 0\n",
    "            \n",
    "            # Select and order features\n",
    "            X = df[self.feature_names]\n",
    "            \n",
    "            # Apply scaling if needed\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X)\n",
    "                X_final = X_scaled\n",
    "            else:\n",
    "                X_final = X\n",
    "            \n",
    "            # Make predictions\n",
    "            probabilities = self.model.predict_proba(X_final)[:, 1]\n",
    "            predictions = self.model.predict(X_final)\n",
    "            \n",
    "            # Add results to dataframe\n",
    "            df['churn_probability'] = probabilities\n",
    "            df['churn_prediction'] = ['Will Churn' if p == 1 else 'Will Stay' for p in predictions]\n",
    "            df['risk_level'] = [self._get_risk_level(p) for p in probabilities]\n",
    "            df['confidence'] = [self._get_confidence_level(p) for p in probabilities]\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch prediction failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_risk_level(self, probability):\n",
    "        \"\"\"Classify risk level based on churn probability.\"\"\"\n",
    "        if probability >= 0.7:\n",
    "            return \"HIGH\"\n",
    "        elif probability >= 0.4:\n",
    "            return \"MEDIUM\"\n",
    "        else:\n",
    "            return \"LOW\"\n",
    "    \n",
    "    def _get_confidence_level(self, probability):\n",
    "        \"\"\"Determine prediction confidence.\"\"\"\n",
    "        # Distance from 0.5 (uncertain)\n",
    "        distance_from_uncertain = abs(probability - 0.5)\n",
    "        \n",
    "        if distance_from_uncertain >= 0.4:\n",
    "            return \"Very High\"\n",
    "        elif distance_from_uncertain >= 0.3:\n",
    "            return \"High\"\n",
    "        elif distance_from_uncertain >= 0.2:\n",
    "            return \"Medium\"\n",
    "        else:\n",
    "            return \"Low\"\n",
    "    \n",
    "    def _get_recommendations(self, probability, customer_data):\n",
    "        \"\"\"Generate business recommendations based on prediction.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if probability >= 0.7:\n",
    "            recommendations.append(\"ğŸš¨ URGENT: Immediate retention intervention required\")\n",
    "            recommendations.append(\"ğŸ“ Schedule personal call with retention specialist\")\n",
    "            recommendations.append(\"ğŸ’° Consider special discount or incentive offer\")\n",
    "            recommendations.append(\"ğŸ“‹ Conduct satisfaction survey to identify issues\")\n",
    "        \n",
    "        elif probability >= 0.4:\n",
    "            recommendations.append(\"âš ï¸ MODERATE RISK: Proactive engagement recommended\")\n",
    "            recommendations.append(\"ğŸ“§ Send targeted retention email campaign\")\n",
    "            recommendations.append(\"ğŸ¯ Offer service upgrade or additional features\")\n",
    "            recommendations.append(\"ğŸ“Š Monitor usage patterns closely\")\n",
    "        \n",
    "        else:\n",
    "            recommendations.append(\"âœ… LOW RISK: Continue standard engagement\")\n",
    "            recommendations.append(\"ğŸ“ˆ Focus on upselling opportunities\")\n",
    "            recommendations.append(\"ğŸ Consider loyalty rewards program\")\n",
    "            recommendations.append(\"ğŸ“± Promote self-service features\")\n",
    "        \n",
    "        # Add specific recommendations based on customer features\n",
    "        if isinstance(customer_data, dict):\n",
    "            if customer_data.get('Contract_Month-to-month', 0) == 1:\n",
    "                recommendations.append(\"ğŸ“„ Offer long-term contract with incentives\")\n",
    "            \n",
    "            if customer_data.get('PaymentMethod_Electronic check', 0) == 1:\n",
    "                recommendations.append(\"ğŸ’³ Promote automatic payment methods\")\n",
    "            \n",
    "            if customer_data.get('tenure', 0) < 12:\n",
    "                recommendations.append(\"ğŸ†• Enhance new customer onboarding experience\")\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _get_key_factors(self, customer_features):\n",
    "        \"\"\"Identify key factors influencing the prediction.\"\"\"\n",
    "        # This is a simplified version - in production, you might use SHAP values\n",
    "        key_factors = []\n",
    "        \n",
    "        # Check some key features (these would be identified from feature importance)\n",
    "        high_risk_indicators = {\n",
    "            'Contract_Month-to-month': 'Month-to-month contract',\n",
    "            'PaymentMethod_Electronic check': 'Electronic check payment',\n",
    "            'PaperlessBilling': 'Paperless billing enabled',\n",
    "            'InternetService_Fiber optic': 'Fiber optic internet service'\n",
    "        }\n",
    "        \n",
    "        for feature, description in high_risk_indicators.items():\n",
    "            if feature in customer_features.index and customer_features[feature] > 0.5:\n",
    "                key_factors.append(description)\n",
    "        \n",
    "        # Check tenure\n",
    "        if 'tenure' in customer_features.index:\n",
    "            tenure = customer_features['tenure']\n",
    "            if tenure < 12:\n",
    "                key_factors.append(f'Short tenure ({tenure:.0f} months)')\n",
    "            elif tenure > 50:\n",
    "                key_factors.append(f'Long tenure ({tenure:.0f} months)')\n",
    "        \n",
    "        # Check monthly charges\n",
    "        if 'MonthlyCharges' in customer_features.index:\n",
    "            charges = customer_features['MonthlyCharges']\n",
    "            if charges > 80:\n",
    "                key_factors.append(f'High monthly charges (${charges:.2f})')\n",
    "            elif charges < 30:\n",
    "                key_factors.append(f'Low monthly charges (${charges:.2f})')\n",
    "        \n",
    "        return key_factors[:5]  # Return top 5 factors\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Return information about the loaded model.\"\"\"\n",
    "        info = {\n",
    "            'model_type': type(self.model).__name__,\n",
    "            'features_count': len(self.feature_names),\n",
    "            'requires_scaling': self.scaler is not None,\n",
    "            'feature_names': self.feature_names\n",
    "        }\n",
    "        \n",
    "        if self.model_metadata is not None:\n",
    "            info.update({\n",
    "                'roc_auc_score': self.model_metadata.get('roc_auc_score'),\n",
    "                'f1_score': self.model_metadata.get('f1_score'),\n",
    "                'accuracy': self.model_metadata.get('accuracy')\n",
    "            })\n",
    "        \n",
    "        return info\n",
    "\n",
    "# Initialize the predictor\n",
    "if model is not None:\n",
    "    predictor = TelcoChurnPredictor(\n",
    "        model=model,\n",
    "        feature_names=feature_names,\n",
    "        scaler=scaler,\n",
    "        model_metadata=model_metadata.to_dict() if 'model_metadata' in locals() else None\n",
    "    )\n",
    "    print(\"\\nâœ… Prediction interface ready!\")\nelse:\n",
    "    print(\"\\nâŒ Cannot initialize predictor - model not loaded\")\n",
    "    predictor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Test Single Customer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single customer prediction with example customers\n",
    "print(\"ğŸ§ª TESTING SINGLE CUSTOMER PREDICTIONS\")\n",
    "\n",
    "if predictor is not None:\n",
    "    # Create example customers with different risk profiles\n",
    "    \n",
    "    # Example 1: High-risk customer\n",
    "    high_risk_customer = {\n",
    "        'tenure': 2,  # Short tenure\n",
    "        'MonthlyCharges': 85.0,  # High charges\n",
    "        'TotalCharges': 170.0,\n",
    "        'Contract_Month-to-month': 1,  # Month-to-month contract\n",
    "        'Contract_One year': 0,\n",
    "        'Contract_Two year': 0,\n",
    "        'PaymentMethod_Electronic check': 1,  # Electronic check\n",
    "        'PaymentMethod_Mailed check': 0,\n",
    "        'PaymentMethod_Bank transfer (automatic)': 0,\n",
    "        'PaymentMethod_Credit card (automatic)': 0,\n",
    "        'PaperlessBilling': 1,\n",
    "        'InternetService_Fiber optic': 1,\n",
    "        'InternetService_DSL': 0,\n",
    "        'SeniorCitizen': 0,\n",
    "        'Partner': 0,\n",
    "        'Dependents': 0\n",
    "    }\n",
    "    \n",
    "    # Example 2: Low-risk customer\n",
    "    low_risk_customer = {\n",
    "        'tenure': 60,  # Long tenure\n",
    "        'MonthlyCharges': 45.0,  # Moderate charges\n",
    "        'TotalCharges': 2700.0,\n",
    "        'Contract_Month-to-month': 0,\n",
    "        'Contract_One year': 0,\n",
    "        'Contract_Two year': 1,  # Two-year contract\n",
    "        'PaymentMethod_Electronic check': 0,\n",
    "        'PaymentMethod_Mailed check': 0,\n",
    "        'PaymentMethod_Bank transfer (automatic)': 1,  # Automatic payment\n",
    "        'PaymentMethod_Credit card (automatic)': 0,\n",
    "        'PaperlessBilling': 0,\n",
    "        'InternetService_Fiber optic': 0,\n",
    "        'InternetService_DSL': 1,\n",
    "        'SeniorCitizen': 0,\n",
    "        'Partner': 1,\n",
    "        'Dependents': 1\n",
    "    }\n",
    "    \n",
    "    # Example 3: Medium-risk customer\n",
    "    medium_risk_customer = {\n",
    "        'tenure': 24,  # Medium tenure\n",
    "        'MonthlyCharges': 70.0,\n",
    "        'TotalCharges': 1680.0,\n",
    "        'Contract_Month-to-month': 0,\n",
    "        'Contract_One year': 1,  # One-year contract\n",
    "        'Contract_Two year': 0,\n",
    "        'PaymentMethod_Electronic check': 0,\n",
    "        'PaymentMethod_Mailed check': 1,\n",
    "        'PaymentMethod_Bank transfer (automatic)': 0,\n",
    "        'PaymentMethod_Credit card (automatic)': 0,\n",
    "        'PaperlessBilling': 1,\n",
    "        'InternetService_Fiber optic': 1,\n",
    "        'InternetService_DSL': 0,\n",
    "        'SeniorCitizen': 1,\n",
    "        'Partner': 0,\n",
    "        'Dependents': 0\n",
    "    }\n",
    "    \n",
    "    # Test predictions\n",
    "    test_customers = [\n",
    "        ('High-Risk Customer', high_risk_customer),\n",
    "        ('Low-Risk Customer', low_risk_customer),\n",
    "        ('Medium-Risk Customer', medium_risk_customer)\n",
    "    ]\n",
    "    \n",
    "    for customer_type, customer_data in test_customers:\n",
    "        print(f\"\\nğŸ” Analyzing {customer_type}:\")\n",
    "        print(\"â”€\" * 50)\n",
    "        \n",
    "        result = predictor.predict_single_customer(customer_data)\n",
    "        \n",
    "        if 'error' not in result:\n",
    "            print(f\"ğŸ“Š Churn Probability: {result['churn_probability']:.1%}\")\n",
    "            print(f\"ğŸ¯ Prediction: {result['prediction']}\")\n",
    "            print(f\"âš ï¸ Risk Level: {result['risk_level']}\")\n",
    "            print(f\"ğŸª Confidence: {result['confidence']}\")\n",
    "            \n",
    "            print(f\"\\nğŸ”‘ Key Factors:\")\n",
    "            for factor in result['key_factors']:\n",
    "                print(f\"  â€¢ {factor}\")\n",
    "            \n",
    "            print(f\"\\nğŸ’¡ Recommendations:\")\n",
    "            for i, rec in enumerate(result['recommendations'][:3], 1):\n",
    "                print(f\"  {i}. {rec}\")\n",
    "        else:\n",
    "            print(f\"âŒ Error: {result['error']}\")\n",
    "    \n",
    "    print(\"\\nâœ… Single customer prediction tests completed!\")\nelse:\n",
    "    print(\"âŒ Cannot test predictions - predictor not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Test Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch prediction\n",
    "print(\"ğŸ“Š TESTING BATCH PREDICTION\")\n",
    "\n",
    "if predictor is not None:\n",
    "    # Load test data (using processed features)\n",
    "    try:\n",
    "        test_data = pd.read_csv('../data/telco_processed_features.csv').head(10)\n",
    "        \n",
    "        # Remove target column for prediction\n",
    "        if 'Churn_Binary' in test_data.columns:\n",
    "            actual_churn = test_data['Churn_Binary'].copy()\n",
    "            test_features = test_data.drop('Churn_Binary', axis=1)\n",
    "        else:\n",
    "            test_features = test_data\n",
    "            actual_churn = None\n",
    "        \n",
    "        print(f\"\\nğŸ”„ Processing {len(test_features)} customers...\")\n",
    "        \n",
    "        # Make batch predictions\n",
    "        batch_results = predictor.predict_batch(test_features)\n",
    "        \n",
    "        if batch_results is not None:\n",
    "            print(f\"âœ… Batch prediction completed!\")\n",
    "            \n",
    "            # Display results summary\n",
    "            display_columns = ['churn_probability', 'churn_prediction', 'risk_level', 'confidence']\n",
    "            if actual_churn is not None:\n",
    "                batch_results['actual_churn'] = ['Churned' if x == 1 else 'Stayed' for x in actual_churn]\n",
    "                display_columns = ['actual_churn'] + display_columns\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ Batch Prediction Results:\")\n",
    "            print(batch_results[display_columns].to_string(index=False))\n",
    "            \n",
    "            # Risk level distribution\n",
    "            print(f\"\\nğŸ“Š Risk Level Distribution:\")\n",
    "            risk_distribution = batch_results['risk_level'].value_counts()\n",
    "            for risk, count in risk_distribution.items():\n",
    "                percentage = count / len(batch_results) * 100\n",
    "                print(f\"  {risk}: {count} customers ({percentage:.1f}%)\")\n",
    "            \n",
    "            # Save batch results\n",
    "            batch_results.to_csv('../data/batch_prediction_results.csv', index=False)\n",
    "            print(f\"\\nğŸ’¾ Batch results saved as '../data/batch_prediction_results.csv'\")\n",
    "            \n",
    "            # Visualize results\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # Risk level distribution\n",
    "            plt.subplot(1, 3, 1)\n",
    "            risk_distribution.plot(kind='bar', color=['green', 'orange', 'red'])\n",
    "            plt.title('Risk Level Distribution')\n",
    "            plt.xlabel('Risk Level')\n",
    "            plt.ylabel('Number of Customers')\n",
    "            plt.xticks(rotation=0)\n",
    "            \n",
    "            # Churn probability distribution\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.hist(batch_results['churn_probability'], bins=10, alpha=0.7, color='blue')\n",
    "            plt.title('Churn Probability Distribution')\n",
    "            plt.xlabel('Churn Probability')\n",
    "            plt.ylabel('Number of Customers')\n",
    "            \n",
    "            # Confidence distribution\n",
    "            plt.subplot(1, 3, 3)\n",
    "            confidence_counts = batch_results['confidence'].value_counts()\n",
    "            plt.pie(confidence_counts.values, labels=confidence_counts.index, autopct='%1.1f%%')\n",
    "            plt.title('Prediction Confidence Distribution')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('../visualizations/batch_prediction_results.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"ğŸ“ˆ Visualization saved as '../visualizations/batch_prediction_results.png'\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"âŒ Batch prediction failed\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Test data not found. Please ensure processed data is available.\")\nelse:\n",
    "    print(\"âŒ Cannot test batch prediction - predictor not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance and business impact\n",
    "print(\"ğŸ“ˆ MODEL PERFORMANCE AND BUSINESS IMPACT ANALYSIS\")\n",
    "\n",
    "if predictor is not None:\n",
    "    # Get model information\n",
    "    model_info = predictor.get_model_info()\n",
    "    \n",
    "    print(f\"\\nğŸ¤– MODEL INFORMATION:\")\n",
    "    print(f\"Model Type: {model_info['model_type']}\")\n",
    "    print(f\"Features Count: {model_info['features_count']}\")\n",
    "    print(f\"Requires Scaling: {model_info['requires_scaling']}\")\n",
    "    \n",
    "    if 'roc_auc_score' in model_info:\n",
    "        print(f\"ROC-AUC Score: {model_info['roc_auc_score']:.4f}\")\n",
    "        print(f\"F1 Score: {model_info['f1_score']:.4f}\")\n",
    "        print(f\"Accuracy: {model_info['accuracy']:.4f}\")\n",
    "    \n",
    "    # Business impact analysis\n",
    "    if 'batch_results' in locals() and batch_results is not None:\n",
    "        print(f\"\\nğŸ’¼ BUSINESS IMPACT ANALYSIS:\")\n",
    "        \n",
    "        total_customers = len(batch_results)\n",
    "        high_risk = len(batch_results[batch_results['risk_level'] == 'HIGH'])\n",
    "        medium_risk = len(batch_results[batch_results['risk_level'] == 'MEDIUM'])\n",
    "        low_risk = len(batch_results[batch_results['risk_level'] == 'LOW'])\n",
    "        \n",
    "        print(f\"ğŸ“Š Customer Risk Distribution:\")\n",
    "        print(f\"  High Risk: {high_risk} customers ({high_risk/total_customers:.1%})\")\n",
    "        print(f\"  Medium Risk: {medium_risk} customers ({medium_risk/total_customers:.1%})\")\n",
    "        print(f\"  Low Risk: {low_risk} customers ({low_risk/total_customers:.1%})\")\n",
    "        \n",
    "        # Estimate potential revenue impact\n",
    "        avg_monthly_revenue = 65  # Estimated average monthly revenue per customer\n",
    "        annual_revenue_per_customer = avg_monthly_revenue * 12\n",
    "        \n",
    "        high_risk_annual_impact = high_risk * annual_revenue_per_customer\n",
    "        medium_risk_annual_impact = medium_risk * annual_revenue_per_customer * 0.5  # 50% chance\n",
    "        \n",
    "        total_at_risk_revenue = high_risk_annual_impact + medium_risk_annual_impact\n",
    "        \n",
    "        print(f\"\\nğŸ’° REVENUE IMPACT ESTIMATION:\")\n",
    "        print(f\"High-risk customers annual revenue: ${high_risk_annual_impact:,.0f}\")\n",
    "        print(f\"Medium-risk customers potential impact: ${medium_risk_annual_impact:,.0f}\")\n",
    "        print(f\"Total at-risk annual revenue: ${total_at_risk_revenue:,.0f}\")\n",
    "        \n",
    "        # Intervention recommendations\n",
    "        print(f\"\\nğŸ¯ INTERVENTION RECOMMENDATIONS:\")\n",
    "        print(f\"1. ğŸš¨ Immediate action for {high_risk} high-risk customers\")\n",
    "        print(f\"2. ğŸ“§ Proactive engagement for {medium_risk} medium-risk customers\")\n",
    "        print(f\"3. ğŸ Loyalty programs for {low_risk} low-risk customers\")\n",
    "        \n",
    "        # Success metrics\n",
    "        retention_scenarios = [\n",
    "            (\"Conservative (10% improvement)\", 0.1),\n",
    "            (\"Moderate (25% improvement)\", 0.25),\n",
    "            (\"Optimistic (50% improvement)\", 0.5)\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nğŸ“Š POTENTIAL RETENTION IMPACT:\")\n",
    "        for scenario, improvement in retention_scenarios:\n",
    "            retained_revenue = total_at_risk_revenue * improvement\n",
    "            print(f\"{scenario}: ${retained_revenue:,.0f} additional annual revenue\")\n",
    "    \n",
    "    print(f\"\\nâœ… Performance analysis completed!\")\nelse:\n",
    "    print(\"âŒ Cannot analyze performance - predictor not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Production Deployment Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create production deployment guide and example usage\n",
    "print(\"ğŸš€ PRODUCTION DEPLOYMENT GUIDE\")\n",
    "\n",
    "deployment_guide = \"\"\"\n",
    "# ğŸ¯ Telco Churn Predictor - Production Deployment Guide\n",
    "\n",
    "## ğŸ“‹ Prerequisites\n",
    "- Python 3.8+\n",
    "- Required packages: pandas, numpy, scikit-learn, joblib\n",
    "- Trained model files in ../models/ directory\n",
    "\n",
    "## ğŸ—ï¸ Quick Start\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from telco_churn_predictor import TelcoChurnPredictor\n",
    "\n",
    "# Load model components\n",
    "model = joblib.load('../models/best_churn_model_*.pkl')\n",
    "feature_names = joblib.load('../models/feature_names.pkl')\n",
    "scaler = joblib.load('../models/feature_scaler.pkl')  # If needed\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = TelcoChurnPredictor(model, feature_names, scaler)\n",
    "\n",
    "# Single customer prediction\n",
    "customer_data = {\n",
    "    'tenure': 12,\n",
    "    'MonthlyCharges': 70.0,\n",
    "    'Contract_Month-to-month': 1,\n",
    "    # ... other features\n",
    "}\n",
    "\n",
    "result = predictor.predict_single_customer(customer_data)\n",
    "print(f\"Churn Probability: {result['churn_probability']:.1%}\")\n",
    "print(f\"Risk Level: {result['risk_level']}\")\n",
    "```\n",
    "\n",
    "## ğŸ“Š Batch Processing\n",
    "\n",
    "```python\n",
    "# Load customer data\n",
    "customers_df = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# Make batch predictions\n",
    "results_df = predictor.predict_batch(customers_df)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('churn_predictions.csv', index=False)\n",
    "```\n",
    "\n",
    "## ğŸ¯ Integration Options\n",
    "\n",
    "### 1. REST API Service\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "predictor = TelcoChurnPredictor(...)  # Initialize\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_churn():\n",
    "    customer_data = request.json\n",
    "    result = predictor.predict_single_customer(customer_data)\n",
    "    return jsonify(result)\n",
    "```\n",
    "\n",
    "### 2. Batch Processing Service\n",
    "```python\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "def daily_churn_analysis():\n",
    "    customers = load_customer_data()\n",
    "    predictions = predictor.predict_batch(customers)\n",
    "    send_alerts_for_high_risk(predictions)\n",
    "\n",
    "schedule.every().day.at(\"09:00\").do(daily_churn_analysis)\n",
    "```\n",
    "\n",
    "### 3. Database Integration\n",
    "```python\n",
    "import sqlite3\n",
    "\n",
    "def update_customer_risk_scores():\n",
    "    conn = sqlite3.connect('customer_db.sqlite')\n",
    "    customers = pd.read_sql('SELECT * FROM customers', conn)\n",
    "    \n",
    "    predictions = predictor.predict_batch(customers)\n",
    "    \n",
    "    # Update risk scores\n",
    "    predictions[['customer_id', 'churn_probability', 'risk_level']].to_sql(\n",
    "        'risk_scores', conn, if_exists='replace', index=False\n",
    "    )\n",
    "```\n",
    "\n",
    "## ğŸ“Š Monitoring and Maintenance\n",
    "\n",
    "1. **Model Performance Tracking**\n",
    "   - Monitor prediction accuracy over time\n",
    "   - Track actual churn vs predicted churn\n",
    "   - Set up alerts for model drift\n",
    "\n",
    "2. **Data Quality Monitoring**\n",
    "   - Validate input features\n",
    "   - Check for missing values\n",
    "   - Monitor feature distributions\n",
    "\n",
    "3. **Business Impact Tracking**\n",
    "   - Measure retention campaign effectiveness\n",
    "   - Track revenue impact of interventions\n",
    "   - Monitor customer satisfaction scores\n",
    "\n",
    "## ğŸ”’ Security Considerations\n",
    "\n",
    "- Encrypt model files in production\n",
    "- Implement proper authentication for API endpoints\n",
    "- Ensure customer data privacy compliance\n",
    "- Log prediction requests for audit trails\n",
    "\n",
    "## ğŸ“ˆ Scaling Recommendations\n",
    "\n",
    "- Use containerization (Docker) for easy deployment\n",
    "- Implement load balancing for high-traffic scenarios\n",
    "- Consider model serving platforms (MLflow, Kubeflow)\n",
    "- Set up automated retraining pipelines\n",
    "\"\"\"\n",
    "\n",
    "# Save deployment guide\n",
    "with open('../docs/DEPLOYMENT_GUIDE.md', 'w') as f:\n",
    "    f.write(deployment_guide)\n",
    "\n",
    "print(\"ğŸ“ Deployment guide created as '../docs/DEPLOYMENT_GUIDE.md'\")\n",
    "\n",
    "# Create example configuration file\n",
    "config_template = {\n",
    "    \"model_path\": \"../models/\",\n",
    "    \"model_files\": {\n",
    "        \"model\": \"best_churn_model_*.pkl\",\n",
    "        \"scaler\": \"feature_scaler.pkl\",\n",
    "        \"features\": \"feature_names.pkl\",\n",
    "        \"metadata\": \"model_metadata.csv\"\n",
    "    },\n",
    "    \"risk_thresholds\": {\n",
    "        \"high_risk\": 0.7,\n",
    "        \"medium_risk\": 0.4\n",
    "    },\n",
    "    \"business_rules\": {\n",
    "        \"min_tenure_for_analysis\": 1,\n",
    "        \"max_monthly_charges\": 200,\n",
    "        \"default_missing_value\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../models/prediction_config.json', 'w') as f:\n",
    "    json.dump(config_template, f, indent=2)\n",
    "\n",
    "print(\"âš™ï¸ Configuration template created as '../models/prediction_config.json'\")\n",
    "\n",
    "print(\"\\nğŸ‰ PRODUCTION SYSTEM READY!\")\n",
    "print(\"\\nğŸ“‹ Available Files:\")\n",
    "print(\"âœ… Trained model and components in ../models/\")\n",
    "print(\"âœ… Prediction interface class (this notebook)\")\n",
    "print(\"âœ… Deployment guide in ../docs/DEPLOYMENT_GUIDE.md\")\n",
    "print(\"âœ… Configuration template in ../models/prediction_config.json\")\n",
    "print(\"âœ… Example predictions and visualizations\")\n",
    "\n",
    "print(\"\\nğŸš€ Next Steps for Production:\")\n",
    "print(\"1. ğŸ³ Containerize the application with Docker\")\n",
    "print(\"2. ğŸŒ Create REST API service\")\n",
    "print(\"3. ğŸ“Š Set up monitoring and alerting\")\n",
    "print(\"4. ğŸ”„ Implement automated retraining pipeline\")\n",
    "print(\"5. ğŸ¯ Deploy to production environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Prediction Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction interface as a standalone Python module\n",
    "interface_code = '''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TelcoChurnPredictor:\n",
    "    \"\"\"\n",
    "    Production-ready churn prediction interface for Telco customers.\n",
    "    \n",
    "    This class provides methods for:\n",
    "    - Single customer churn prediction\n",
    "    - Batch prediction for multiple customers\n",
    "    - Risk level classification\n",
    "    - Business recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path=None, model=None, feature_names=None, scaler=None):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with trained model and components.\n",
    "        \n",
    "        Parameters:\n",
    "        - model_path: Path to directory containing model files\n",
    "        - model: Trained machine learning model (if loading directly)\n",
    "        - feature_names: List of feature names expected by the model\n",
    "        - scaler: Feature scaler (if model requires scaling)\n",
    "        \"\"\"\n",
    "        if model_path:\n",
    "            self._load_from_path(model_path)\n",
    "        else:\n",
    "            self.model = model\n",
    "            self.feature_names = feature_names\n",
    "            self.scaler = scaler\n",
    "        \n",
    "        print(f\"ğŸ¤– TelcoChurnPredictor initialized\")\n",
    "        print(f\"   Model: {type(self.model).__name__}\")\n",
    "        print(f\"   Features: {len(self.feature_names)}\")\n",
    "        print(f\"   Scaling: {'Yes' if self.scaler is not None else 'No'}\")\n",
    "    \n",
    "    def _load_from_path(self, model_path):\n",
    "        \"\"\"Load model components from file path.\"\"\"\n",
    "        import glob\n",
    "        import os\n",
    "        \n",
    "        # Find model file\n",
    "        model_files = glob.glob(os.path.join(model_path, 'best_churn_model_*.pkl'))\n",
    "        if not model_files:\n",
    "            raise FileNotFoundError(f\"No model file found in {model_path}\")\n",
    "        \n",
    "        self.model = joblib.load(model_files[0])\n",
    "        self.feature_names = joblib.load(os.path.join(model_path, 'feature_names.pkl'))\n",
    "        \n",
    "        # Load scaler if exists\n",
    "        scaler_path = os.path.join(model_path, 'feature_scaler.pkl')\n",
    "        if os.path.exists(scaler_path):\n",
    "            self.scaler = joblib.load(scaler_path)\n",
    "        else:\n",
    "            self.scaler = None\n",
    "    \n",
    "    def predict_single_customer(self, customer_data):\n",
    "        \"\"\"Predict churn probability for a single customer.\"\"\"\n",
    "        try:\n",
    "            # Convert to DataFrame if needed\n",
    "            if isinstance(customer_data, dict):\n",
    "                df = pd.DataFrame([customer_data])\n",
    "            elif isinstance(customer_data, pd.Series):\n",
    "                df = pd.DataFrame([customer_data])\n",
    "            else:\n",
    "                df = customer_data\n",
    "            \n",
    "            # Ensure all required features are present\n",
    "            for feature in self.feature_names:\n",
    "                if feature not in df.columns:\n",
    "                    df[feature] = 0\n",
    "            \n",
    "            # Select and order features\n",
    "            X = df[self.feature_names]\n",
    "            \n",
    "            # Apply scaling if needed\n",
    "            if self.scaler is not None:\n",
    "                X_final = self.scaler.transform(X)\n",
    "            else:\n",
    "                X_final = X\n",
    "            \n",
    "            # Make prediction\n",
    "            churn_probability = self.model.predict_proba(X_final)[0, 1]\n",
    "            prediction = self.model.predict(X_final)[0]\n",
    "            \n",
    "            return {\n",
    "                'churn_probability': round(churn_probability, 4),\n",
    "                'prediction': 'Will Churn' if prediction == 1 else 'Will Stay',\n",
    "                'risk_level': self._get_risk_level(churn_probability),\n",
    "                'confidence': self._get_confidence_level(churn_probability),\n",
    "                'recommendations': self._get_recommendations(churn_probability, customer_data)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': f\"Prediction failed: {str(e)}\"}\n",
    "    \n",
    "    def predict_batch(self, customers_data):\n",
    "        \"\"\"Predict churn for multiple customers.\"\"\"\n",
    "        try:\n",
    "            df = customers_data.copy()\n",
    "            \n",
    "            # Ensure all required features are present\n",
    "            for feature in self.feature_names:\n",
    "                if feature not in df.columns:\n",
    "                    df[feature] = 0\n",
    "            \n",
    "            # Select and order features\n",
    "            X = df[self.feature_names]\n",
    "            \n",
    "            # Apply scaling if needed\n",
    "            if self.scaler is not None:\n",
    "                X_final = self.scaler.transform(X)\n",
    "            else:\n",
    "                X_final = X\n",
    "            \n",
    "            # Make predictions\n",
    "            probabilities = self.model.predict_proba(X_final)[:, 1]\n",
    "            predictions = self.model.predict(X_final)\n",
    "            \n",
    "            # Add results to dataframe\n",
    "            df['churn_probability'] = probabilities\n",
    "            df['churn_prediction'] = ['Will Churn' if p == 1 else 'Will Stay' for p in predictions]\n",
    "            df['risk_level'] = [self._get_risk_level(p) for p in probabilities]\n",
    "            df['confidence'] = [self._get_confidence_level(p) for p in probabilities]\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch prediction failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_risk_level(self, probability):\n",
    "        \"\"\"Classify risk level based on churn probability.\"\"\"\n",
    "        if probability >= 0.7:\n",
    "            return \"HIGH\"\n",
    "        elif probability >= 0.4:\n",
    "            return \"MEDIUM\"\n",
    "        else:\n",
    "            return \"LOW\"\n",
    "    \n",
    "    def _get_confidence_level(self, probability):\n",
    "        \"\"\"Determine prediction confidence.\"\"\"\n",
    "        distance_from_uncertain = abs(probability - 0.5)\n",
    "        \n",
    "        if distance_from_uncertain >= 0.4:\n",
    "            return \"Very High\"\n",
    "        elif distance_from_uncertain >= 0.3:\n",
    "            return \"High\"\n",
    "        elif distance_from_uncertain >= 0.2:\n",
    "            return \"Medium\"\n",
    "        else:\n",
    "            return \"Low\"\n",
    "    \n",
    "    def _get_recommendations(self, probability, customer_data):\n",
    "        \"\"\"Generate business recommendations based on prediction.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if probability >= 0.7:\n",
    "            recommendations.extend([\n",
    "                \"ğŸš¨ URGENT: Immediate retention intervention required\",\n",
    "                \"ğŸ“ Schedule personal call with retention specialist\",\n",
    "                \"ğŸ’° Consider special discount or incentive offer\"\n",
    "            ])\n",
    "        elif probability >= 0.4:\n",
    "            recommendations.extend([\n",
    "                \"âš ï¸ MODERATE RISK: Proactive engagement recommended\",\n",
    "                \"ğŸ“§ Send targeted retention email campaign\",\n",
    "                \"ğŸ¯ Offer service upgrade or additional features\"\n",
    "            ])\n",
    "        else:\n",
    "            recommendations.extend([\n",
    "                \"âœ… LOW RISK: Continue standard engagement\",\n",
    "                \"ğŸ“ˆ Focus on upselling opportunities\",\n",
    "                \"ğŸ Consider loyalty rewards program\"\n",
    "            ])\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize predictor\n",
    "    predictor = TelcoChurnPredictor(model_path=\"../models/\")\n",
    "    \n",
    "    # Example prediction\n",
    "    customer = {\n",
    "        'tenure': 12,\n",
    "        'MonthlyCharges': 70.0,\n",
    "        'Contract_Month-to-month': 1\n",
    "    }\n",
    "    \n",
    "    result = predictor.predict_single_customer(customer)\n",
    "    print(f\"Churn Probability: {result['churn_probability']:.1%}\")\n",
    "    print(f\"Risk Level: {result['risk_level']}\")\n",
    "'''\n",
    "\n",
    "# Save the interface module\n",
    "with open('../src/telco_churn_predictor.py', 'w') as f:\n",
    "    f.write(interface_code)\n",
    "\n",
    "print(\"ğŸ’¾ Prediction interface saved as '../src/telco_churn_predictor.py'\")\n",
    "print(\"\\nâœ… PREDICTION INTERFACE COMPLETE!\")\n",
    "print(\"\\nğŸ“‹ Summary of Deliverables:\")\n",
    "print(\"âœ… 5 Comprehensive Jupyter notebooks\")\n",
    "print(\"âœ… Trained machine learning model\")\n",
    "print(\"âœ… Production-ready prediction interface\")\n",
    "print(\"âœ… Business insights and recommendations\")\n",
    "print(\"âœ… Deployment guide and documentation\")\n",
    "print(\"âœ… Visualizations and analysis reports\")\n",
    "print(\"\\nğŸ¯ Ready for production deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}